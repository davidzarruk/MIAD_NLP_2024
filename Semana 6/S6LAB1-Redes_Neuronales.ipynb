{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "En este notebook aprenderá a construir y a entrenar redes neuronales de una capa y multicapas, usando la librería [Keras](https://keras.io/).\n",
    "\n",
    "Este notebook tiene una licencia de [Creative Commons Attribution-ShareAlike 3.0 Unported License](http://creativecommons.org/licenses/by-sa/3.0/deed.en_US). Un agradecimiento especial para [Valerio Maggio](https://mpba.fbk.eu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones Generales\n",
    "\n",
    "Keras es una librería de redes neuronales altamente modular, escrita en Python y capaz de ejecutarse sobre TensorFlow o Theano. Fue desarrollada con el objetivo de permitir una experimentación rápida con modelos de redes neuronales.\n",
    "\n",
    "Este notebook esta compuesto por dos secciones. En la primera sección, usted beberá construir y entrenar una red neuronal de una capa para predecir el precio de una casa con el set de datos Boston Housing Data. En la segunda parte, se usará el mismo dataset pero usted beberá construir y entrenar una red neuronal multicapa para identificar sus ventajas. Para conocer más detalles de la base, puede ingresar al siguiente [vínculo](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/).\n",
    "   \n",
    "Para realizar la actividad, solo siga las indicaciones asociadas a cada celda del notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar base de datos y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "# Carga de datos de la librería sklearn\n",
    "boston_dataset = load_boston()\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de variables predictoras  y de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variables predictoras (X)\n",
    "X = boston.drop(boston.columns[-1],axis=1)\n",
    "# Definición de variable de interés (y)\n",
    "Y = pd.DataFrame(np.array(boston_dataset.target), columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test usandola función train_test_split\n",
    "X_train, X_test , Y_train, Y_test = train_test_split(X,Y, test_size=0.3 ,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de variables predictoras (X) con la función StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definición de la función StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Transformación de los set de entrenamiento y test\n",
    "X_train = pd.DataFrame(data=scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de dimensiones de salida, varaibles de interés\n",
    "output_var = Y_train.shape[1]\n",
    "print(output_var, ' output variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de dimensiones de entrada, varaibles predictoras\n",
    "dims = X_train.shape[1]\n",
    "print(dims, 'input variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal de una sola capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras import backend as K\n",
    "import keras.optimizers as opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Definición red neuronal con la función Sequential()\n",
    "model = Sequential()\n",
    "# Definición de la capa densa con un tamaño de salida igual a output_var y un input_shape de dims\n",
    "model.add(Dense(output_var, input_shape=(dims,)))\n",
    "\n",
    "# Impresión de la arquitectura de la red neuronal\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de función de perdida. Se usa mean_squared_error dado que es un ejercicio de regresión\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Entrenamiento de la red neuronal con 50 épocas\n",
    "model.fit(X_train, Y_train, \n",
    "          verbose=1, \n",
    "          epochs=50, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[PlotLossesKeras()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal de una sola capa con early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Definición red neuronal con la función Sequential()\n",
    "model = Sequential()\n",
    "# Definición de la capa densa con un tamaño de salida igual a output_var y un input_shape de dims\n",
    "model.add(Dense(output_var, input_shape=(dims,)))\n",
    "# Definición de función de perdida. Se usa mean_squared_error dado que es un ejercicio de regresión\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# Impresión de la arquitectura de la red neuronal\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función EarlyStopping para considerar durante el entrenamiento\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función ModelCheckpoint para guardar el modelo con mejor desempeño\n",
    "fBestModel = 'best_model.h5'\n",
    "best_model = ModelCheckpoint(fBestModel, verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamiento de la red neuronal con 50 épocas y early stopping\n",
    "model.fit(X_train, Y_train, \n",
    "          verbose=True, \n",
    "          epochs=50, \n",
    "          batch_size=128,\n",
    "          validation_data=(X_test,Y_test),\n",
    "          callbacks=[best_model, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Definición red neuronal con la función Sequential()\n",
    "model = Sequential()\n",
    "\n",
    "# Definición de la capa densa con un tamaño de salida igual a output_var y un input_shape de dims\n",
    "model.add(Dense(256, input_shape=(dims,),activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(output_var))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Impresión de la arquitectura de la red neuronal\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de función de perdida. Se usa mean_squared_error dado que es un ejercicio de regresión\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos de entrenamiento para considerar un set de validación durante entrenamiento\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de la red neuronal con 50 épocas\n",
    "model.fit(X_train, Y_train,\n",
    "          validation_data = (X_val, Y_val),\n",
    "          epochs=50, \n",
    "          callbacks=[PlotLossesKeras()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
